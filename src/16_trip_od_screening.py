"""Trip OD screening script.

This script cross-references trip CSV files generated by ``15_trip_extractor.py``
with "様式1-3" CSV files contained inside ZIP archives. It builds a trip index
based on file names, constructs a lookup dictionary from the ZIP contents, and
finally outputs an extracted subset of "様式1-3" rows that correspond to the
trips in the index. Missing matches produce blank rows so that the output row
count always aligns with the index.
"""

# 本スクリプトは、処理の大まかな進捗が分かるように、5%刻み程度でログを出力します。
# ファイル件数や行数が多い場合でも、ログが多くなりすぎないよう配慮しています。

from __future__ import annotations

import csv
import io
import zipfile
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Iterable, Sequence
import math


def log(msg: str) -> None:
    """時刻付きで1行ログを出す簡易ヘルパ。"""

    now = datetime.now().strftime("%H:%M:%S")
    print(f"[{now}] {msg}")

# ---------------------------------------------------------------------------
# Configuration (edit as needed before running the script)
# ---------------------------------------------------------------------------
# 15_trip_extractor.py が出力したトリップCSVファイル群を格納しているフォルダ
TRIP_CSV_DIR = Path(r"C:\\path\\to\\15_trip_output")

# 一覧CSV（ファイル名一覧＋付加情報）の出力先パス
TRIP_INDEX_CSV_PATH = Path(r"C:\\path\\to\\trip_index.csv")

# 様式1-3 抜粋結果CSVの出力先パス
RESULT_CSV_PATH = Path(r"C:\\path\\to\\trip_od_result.csv")

# 様式1-3 の ZIP ファイルが格納されているフォルダ（最大9個）
ZIP_DIRS: list[Path] = [
    Path(r"C:\\path\\to\\folder_a"),
    Path(r"C:\\path\\to\\folder_b"),
    # 使わないスロットは None またはコメントアウトでよい
    # None,
]

# 一覧CSVと結果CSVのエンコーディング
FILE_ENCODING = "utf-8-sig"


@dataclass
class TripIndexEntry:
    """Container for trip index information parsed from file names."""

    route_name: str
    weekday_name: str
    operation_id: str
    operation_date: str
    trip_number: str
    vehicle_type_code: str
    vehicle_use_code: str


# ---------------------------------------------------------------------------
# Utility functions
# ---------------------------------------------------------------------------

def vehicle_type_label(code: str) -> str:
    """Convert vehicle type code (E**) into a descriptive label."""

    if code.startswith("E") and len(code) >= 3 and code[1:].isdigit():
        number = int(code[1:])
        if number == 0:
            return "0:軽二輪"
        if number == 1:
            return "1:大型"
        if number == 2:
            return "2:普通"
        if number == 3:
            return "3:小型"
        if number == 4:
            return "4:軽自動車"
        if 5 <= number <= 15:
            return "5～15:未定義"
    return "その他:未定義"


def vehicle_use_label(code: str) -> str:
    """Convert vehicle use code (F**) into a descriptive label."""

    if code.startswith("F") and len(code) >= 3 and code[1:].isdigit():
        number = int(code[1:])
        if number == 0:
            return "0:未使用"
        if number == 1:
            return "1:乗用"
        if number == 2:
            return "2:貨物"
        if number == 3:
            return "3:特殊"
        if number == 4:
            return "4:乗合"
        if 5 <= number <= 15:
            return "5～15:未定義"
    return "その他:未定義"


def parse_trip_filename(path: Path) -> TripIndexEntry | None:
    """Parse a trip CSV file name into a :class:`TripIndexEntry`.

    Expected format (example):
    ``2nd_<route>_<weekday>_ID000000061071_20250124_t001_E02_F01.csv``

    - operation_id: strip leading "ID" → "000000061071"
    - trip_number : strip leading "t"  → "001"
    """

    stem = path.stem
    parts = stem.split("_")
    if len(parts) < 8 or parts[0] != "2nd":
        log(f"[WARN] Invalid file name format, skipping: {path.name}")
        return None

    route_name = parts[1]
    weekday_name = parts[2]

    raw_operation_id = parts[3]
    raw_operation_date = parts[4]
    raw_trip_number = parts[5]
    vehicle_type_code = parts[6]
    vehicle_use_code = parts[7]

    if raw_operation_id.upper().startswith("ID"):
        operation_id = raw_operation_id[2:]
    else:
        operation_id = raw_operation_id
    if len(operation_id) != 12 or not operation_id.isdigit():
        log(
            f"[WARN] Operation ID does not look like 12-digit numeric: "
            f"{raw_operation_id} -> {operation_id} (file: {path.name})"
        )

    if raw_trip_number.lower().startswith("t"):
        trip_number = raw_trip_number[1:]
    else:
        trip_number = raw_trip_number

    return TripIndexEntry(
        route_name=route_name,
        weekday_name=weekday_name,
        operation_id=operation_id,
        operation_date=raw_operation_date,
        trip_number=trip_number,
        vehicle_type_code=vehicle_type_code,
        vehicle_use_code=vehicle_use_code,
    )


def build_trip_index(trip_csv_files: Sequence[Path]) -> list[TripIndexEntry]:
    """Scan the trip CSV paths and return parsed entries."""

    entries: list[TripIndexEntry] = []
    for csv_path in trip_csv_files:
        entry = parse_trip_filename(csv_path)
        if entry is None:
            continue
        entries.append(entry)
    log(f"インデックス対象のトリップCSV件数: {len(entries)} 件")
    return entries


def write_trip_index(entries: Sequence[TripIndexEntry], output_path: Path) -> None:
    """Write the trip index CSV based on parsed entries."""

    output_path.parent.mkdir(parents=True, exist_ok=True)
    data_rows_count = len(entries)
    header = [
        "スクリーニング区分",
        "ルート名",
        "曜日名",
        "運行ID",
        "運行日",
        "トリップ番号",
        "自動車の種別",
        "自動車の用途",
    ]
    with output_path.open("w", encoding=FILE_ENCODING, newline="") as f:
        writer = csv.writer(f)
        writer.writerow(header)
        for entry in entries:
            try:
                trip_no_value: str | int = int(entry.trip_number)
            except ValueError:
                trip_no_value = entry.trip_number
            writer.writerow(
                [
                    "第2スクリーニング",
                    entry.route_name,
                    entry.weekday_name,
                    entry.operation_id,
                    entry.operation_date,
                    trip_no_value,
                    vehicle_type_label(entry.vehicle_type_code),
                    vehicle_use_label(entry.vehicle_use_code),
                ]
            )
    log(
        f"一覧CSVを出力しました: {output_path} （データ行数: {data_rows_count} 行）"
    )


def _read_csv_rows_from_zip_member(zf: zipfile.ZipFile, info: zipfile.ZipInfo) -> list[list[str]]:
    """Read CSV rows from a ZIP member with encoding fallbacks."""

    for encoding in ("cp932", "utf-8-sig", "utf-8"):
        try:
            with zf.open(info) as fp:
                text = io.TextIOWrapper(fp, encoding=encoding, errors="replace", newline="")
                return list(csv.reader(text))
        except UnicodeDecodeError:
            continue
    log(f"[WARN] Failed to decode CSV in ZIP member: {info.filename}")
    return []


def _is_youshiki_header(header: list[str]) -> bool:
    """Heuristic check for 様式1-3 header."""

    if len(header) < 18:
        return False
    h0 = header[0]
    h1 = header[1]
    h7 = header[7]
    return (
        ("運行日" in h0)
        and ("運行ID" in h1)
        and ("トリップ" in h7 or "ﾄﾘｯﾌﾟ" in h7)
    )


def _normalize_trip_number(token: str) -> tuple[list[str], list[int]]:
    """Return canonical string and integer representations for trip number."""

    strings: list[str] = []
    integers: list[int] = []
    cleaned = token.strip()
    if cleaned:
        strings.append(cleaned)
        if cleaned.isdigit():
            number = int(cleaned)
            integers.append(number)
            strings.append(f"{number:03d}")
    return strings, integers


def build_youshiki_dictionary(zip_paths: Iterable[Path]):
    """Build lookup dictionary from 様式1-3 CSV files inside ZIP archives."""

    lookup: dict[tuple[str, str, str | int], list[str]] = {}
    header: list[str] | None = None
    total_rows = 0
    zip_list = list(zip_paths)

    zip_total = len(zip_list)
    log("様式1-3の検索・辞書化を開始します。")

    if zip_total == 0:
        log("処理対象のZIPファイルがありません。")
        return header, lookup

    zip_start_time = datetime.now()
    next_progress = 0

    for idx, zip_path in enumerate(zip_list, start=1):
        if zip_path is None or str(zip_path).strip() == "":
            continue
        if not zip_path.exists():
            log(f"[WARN] ZIP file not found, skipping: {zip_path}")
            continue

        zip_row_hits = 0
        log(f"Processing ZIP: {zip_path}")
        with zipfile.ZipFile(zip_path) as zf:
            for info in zf.infolist():
                if info.is_dir() or not info.filename.lower().endswith(".csv"):
                    continue
                rows = _read_csv_rows_from_zip_member(zf, info)
                if not rows:
                    continue
                csv_header = rows[0]
                if not _is_youshiki_header(csv_header):
                    continue
                if header is None:
                    header = csv_header
                for row in rows[1:]:
                    if len(row) < 8:
                        continue
                    op_date = row[0].strip()
                    op_id = row[1].strip()
                    trip_token = row[7].strip()
                    if not op_date or not op_id or not trip_token:
                        continue
                    string_keys, int_keys = _normalize_trip_number(trip_token)
                    # Prefer the first occurrence of a key; skip duplicates.
                    row_data = row
                    if header:
                        # Normalize row length to header length for consistent output.
                        row_data = (row + [""] * len(header))[: len(header)]
                    zip_row_hits += 1
                    total_rows += 1
                    for trip_no in int_keys:
                        key = (op_date, op_id, trip_no)
                        if key not in lookup:
                            lookup[key] = row_data
                    for trip_no in string_keys:
                        key = (op_date, op_id, trip_no)
                        if key not in lookup:
                            lookup[key] = row_data

        log(
            f"ZIP内様式1-3ヒット行数: {zip_row_hits} 行 "
            f"(累計: {total_rows} 行, file={zip_path.name})"
        )

        progress = idx / zip_total
        percent = int(progress * 100)

        if percent >= next_progress:
            elapsed = (datetime.now() - zip_start_time).total_seconds()
            if progress > 0 and elapsed > 1.0:
                est_total = elapsed / progress
                est_remaining = est_total - elapsed
                eta = datetime.now() + timedelta(seconds=est_remaining)
                eta_str = eta.strftime("%H:%M:%S")
                log(f"ZIP処理進捗: {percent:3d}% ({idx}/{zip_total}) 予想終了時刻: {eta_str}")
            else:
                log(f"ZIP処理進捗: {percent:3d}% ({idx}/{zip_total})")

            next_progress += 5

    log(f"様式1-3の辞書化完了。登録行数: {total_rows} 行、ユニークキー数: {len(lookup)} 件")
    return header, lookup


def _load_trip_index_rows(index_path: Path) -> list[list[str]]:
    """Load the trip index CSV rows (excluding header)."""

    with index_path.open("r", encoding=FILE_ENCODING, newline="") as f:
        reader = csv.reader(f)
        rows = list(reader)
    return rows[1:]


def _match_index_to_lookup(
    index_rows: Sequence[list[str]],
    header: list[str],
    lookup: dict[tuple[str, str, str | int], list[str]],
) -> tuple[list[list[str]], int, int]:
    """Match index rows to lookup dictionary and return output rows and hit count."""

    output_rows: list[list[str]] = []
    matched_count = 0
    unmatched_count = 0
    blank_row = [""] * len(header)

    index_total = len(index_rows)
    log(f"一覧CSVとのマッチングを開始します。対象件数: {index_total} 行")

    match_start_time = datetime.now()
    next_progress = 0

    for i, row in enumerate(index_rows, start=1):
        if len(row) < 6:
            unmatched_count += 1
            output_rows.append(blank_row)
            continue
        op_id = row[3].strip()
        op_date = row[4].strip()
        trip_token = row[5].strip()
        string_keys, int_keys = _normalize_trip_number(trip_token)
        candidates = []
        candidates.extend((op_date, op_id, key) for key in int_keys)
        candidates.extend((op_date, op_id, key) for key in string_keys)

        matched_row = None
        for key in candidates:
            if key in lookup:
                matched_row = lookup[key]
                break
        if matched_row is not None:
            matched_count += 1
            output_rows.append(matched_row)
        else:
            unmatched_count += 1
            output_rows.append(blank_row)

        progress = i / index_total if index_total else 0
        percent = int(progress * 100)
        if percent >= next_progress and index_total:
            elapsed = (datetime.now() - match_start_time).total_seconds()
            if progress > 0 and elapsed > 1.0:
                est_total = elapsed / progress
                est_remaining = est_total - elapsed
                eta = datetime.now() + timedelta(seconds=est_remaining)
                eta_str = eta.strftime("%H:%M:%S")
                log(
                    f"マッチング進捗: {percent:3d}% ({i}/{index_total}) 予想終了時刻: {eta_str}"
                )
            else:
                log(f"マッチング進捗: {percent:3d}% ({i}/{index_total})")

            next_progress += 5

    log(
        f"マッチング完了。ヒット件数: {matched_count} 行、未ヒット件数: {unmatched_count} 行"
    )
    return output_rows, matched_count, unmatched_count


def write_result_csv(header: list[str], rows: Sequence[list[str]], output_path: Path) -> None:
    """Write the 様式1-3 extraction result CSV."""

    output_path.parent.mkdir(parents=True, exist_ok=True)
    result_rows_count = len(rows)
    with output_path.open("w", encoding=FILE_ENCODING, newline="") as f:
        writer = csv.writer(f)
        writer.writerow(header)
        writer.writerows(rows)
    log(
        f"出力結果CSVを保存しました: {output_path} （データ行数: {result_rows_count} 行）"
    )


# ---------------------------------------------------------------------------
# Main workflow
# ---------------------------------------------------------------------------

def main() -> None:
    start_time = datetime.now()
    log("16_trip_od_screening を開始します。")
    log(f"TRIP_CSV_DIR = {TRIP_CSV_DIR}")
    log(f"ZIP_DIRS = {[str(d) for d in ZIP_DIRS if d]}")

    trip_csv_files = sorted(TRIP_CSV_DIR.glob("*.csv"))
    log(f"TRIP_CSV_DIR 内のトリップCSV検出: {len(trip_csv_files)} 件。")

    if not trip_csv_files:
        log("トリップCSVが見つかりませんでした。処理を終了します。")
        end_time = datetime.now()
        elapsed = end_time - start_time
        log(f"処理が完了しました。経過時間: {elapsed}. (開始: {start_time}, 終了: {end_time})")
        return

    entries = build_trip_index(trip_csv_files)
    write_trip_index(entries, TRIP_INDEX_CSV_PATH)

    zip_files: list[Path] = []
    valid_zip_dirs: list[Path] = []
    for d in ZIP_DIRS:
        if d and d.exists() and d.is_dir():
            valid_zip_dirs.append(d)
            zip_files.extend(sorted(d.glob("*.zip")))
        elif d:
            log(f"警告: ZIP_DIRS に指定されたフォルダが存在しません: {d}")

    log(f"有効なZIPフォルダ数: {len(valid_zip_dirs)} 個")
    log(f"ZIPファイル総数: {len(zip_files)} 個")

    total_zip_size = math.fsum(p.stat().st_size for p in zip_files) if zip_files else 0
    total_zip_size_mb = total_zip_size / (1024 * 1024)
    log(f"ZIPファイル総容量: {total_zip_size_mb:.1f} MB")
    if not zip_files:
        log("ZIPファイルがありません。空の辞書で処理を継続します。")
        # ZIPファイルがない場合でも以降の処理は続行し、空の辞書でマッチングします。

    header, lookup = build_youshiki_dictionary(zip_files)
    if header is None:
        header = ["運行日", "運行ID"] + [f"Col{i}" for i in range(3, 19)]
        log("[WARN] No 様式1-3 header detected; using fallback header.")

    index_rows = _load_trip_index_rows(TRIP_INDEX_CSV_PATH)
    matched_rows, matched_count, unmatched_count = _match_index_to_lookup(
        index_rows, header, lookup
    )
    log(f"Matched {matched_count} / {len(index_rows)} index rows.")

    if len(matched_rows) != len(index_rows):
        log(
            f"[WARN] Output row count ({len(matched_rows)}) does not match index ({len(index_rows)})."
        )

    write_result_csv(header, matched_rows, RESULT_CSV_PATH)

    end_time = datetime.now()
    elapsed = end_time - start_time
    log(f"処理が完了しました。経過時間: {elapsed}. (開始: {start_time}, 終了: {end_time})")


if __name__ == "__main__":
    main()
