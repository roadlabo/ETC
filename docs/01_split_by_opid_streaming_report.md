# split_by_opid_streaming.py 技術レポート（保存版）

## 概要（まず全体像）

* **目的**：多数のZIP内 `data.csv` から、**運行ID（4列目）**ごとにレコードを抜き出し、`<時期名>_<運行ID>.csv` として**1ファイルに集約**する。
* **方式**：

  1. **ストリーミング抽出**（解凍せず読み→逐次追記／temp大量生成なし）
  2. 抽出完了後、**後処理ソート**（各OPIDファイルを **7列目（0始まり6）** のGPS時刻で**昇順**に外部ソート：チャンク分割＋k-wayマージ）
* **入出力前提**：**ヘッダーは一切なし**（入力も出力も）
* **進捗表示**：コンソールに **2段階の％のみ**を表示

  * `Extract: XX%`（ZIPスキャンの進捗）
  * `Sort: XX%`（OPIDファイルの最終整列の進捗）
    ※ 個々のファイル名などの詳細ログは出さない
* **想定データ**：ETC2.0 様式Ⅰ-2 走行履歴情報（CSV）相当

  * 4列目：運行ID
  * 7列目：GPS時刻（`YYYYMMDDHHMMSS` または `YYYYMMDDHHMM`）
  * 15列目：緯度、16列目：経度、13列目：起終点フラグ（など）
* **成果物**：`OUTPUT_DIR` に `<時期名>_<運行ID>.csv` が並ぶ。内容は**時系列昇順**。

---

## とても詳しい説明（仕様・内部動作・運用のコツ）

### 1. 主要設定（先頭の定数ブロック）

* **パス／対象定義**

  * `INPUT_DIR`：ZIP が入っている親フォルダ
  * `OUTPUT_DIR`：OPIDごとの出力先
  * `TERM_NAME`：ファイル名のプレフィックス（例：`R7_2`）
  * `INNER_CSV`：ZIP内で読むCSV名（既定：`data.csv`）
  * `ZIP_DIGIT_KEYS`：ZIPファイル名に含まれていれば対象とする**4種の数字キー**（例：`["523337","523347","523357","523367"]`）
* **CSV I/O**

  * `ENCODING`：入出力の文字コード（標準は `utf-8`。日本語CSVで文字化けが出るなら `cp932` に変更可）
  * `DELIM`：区切り文字（カンマ）
* **抽出挙動**

  * `BUFFER_SIZE`：読み取りバッファ（例：8MiB）
  * `SHOW_PROGRESS=True`：％進捗を出すか
* **最終ソート（後処理）**

  * `DO_FINAL_SORT=True`：抽出後に整列を行う
  * `TIMESTAMP_COL=6`：**0始まり**で7列目をソートキーにする
  * `SORT_GLOB=f"{TERM_NAME}_*.csv"`：後処理対象のパターン
  * `CHUNK_ROWS=200_000`：チャンク分割の行数（メモリに合わせて 100k～1M で調整）
  * `TEMP_SORT_DIR="_sort_tmp"`：チャンク一時置き場（`OUTPUT_DIR`配下に作成）

> **重要**：ヘッダーは**存在しない前提**。抽出時に**先頭行を飛ばさない**／出力にも**ヘッダーを書かない**。

---

### 2. 入力要件と前提

* **ZIP名フィルタ**：`ZIP_DIGIT_KEYS` のどれかを含むZIPだけを処理。
* **ZIP内部**：`INNER_CSV`（通常 `data.csv`）を**解凍せず**順次読み取り。
* **CSV行の前提**：

  * **4列目**に運行ID（OPID）
  * **7列目**にGPS時刻（`YYYYMMDDHHMMSS` 14桁、または `YYYYMMDDHHMM` 12桁）
  * 行は**ヘッダーなし**でデータのみ
  * 列不足や空行はスキップ

---

### 3. 抽出フェーズ（ストリーミング）

* 処理の流れ

  1. `INPUT_DIR` を走査し、フィルタに合うZIPの総数をカウント（`total_zips`）
  2. 各ZIPを開き、`INNER_CSV` をストリーム読み取り
  3. 1行ずつ **運行ID（4列目）** を取り出し、`<TERM_NAME>_<OPID>.csv` に**追記**

     * **ヘッダーはなし**。受け取った行を**そのまま**書く
     * FD（ファイルディスクリプタ）制限に配慮し、**同時オープンは最小限**
  4. ZIP1個ごとに `processed_zips += 1` → `Extract: XX%` を上書き表示
  5. 全ZIP完了後、行頭に戻さず `Extract` の進捗行を改行して確定
* **利点**：

  * tempの大量生成を避け、**I/Oの無駄を削減**
  * **メモリに載せない**ので大規模データでも安定
* **注意**：

  * 抽出直後のOPIDファイルは「**読み込み順**」で並ぶ。ZIP間で前後するため、**時系列保証は後処理**で行う（次章）。

---

### 4. 後処理ソート（外部ソート）

* 目的：各 `<TERM_NAME>_<OPID>.csv` を **7列目（0始まり6）の時刻**で昇順に並べ替える
* **タイムスタンプ正規化**：

  * 14桁：`YYYYMMDDHHMMSS` → そのまま整数化
  * 12桁：`YYYYMMDDHHMM` → 秒 `00` を補完して14桁化
  * 数値でない／桁不正 → **非常に大きなキー**（末尾に回す）
* **チャンク分割**：

  1. ファイルを上から `CHUNK_ROWS` 件ずつ読み取り、**チャンク内で時刻ソート**
  2. `OUTPUT_DIR/_sort_tmp/<ファイル名>/chunk_*.csv` に順次書き出し
* **k-wayマージ**：

  * 複数の“ソート済みチャンク”を**最小ヒープ**でマージし、`<元ファイル>.sorted.tmp` に1本化
  * 完了後に `os.replace()` で**原本と置き換え**
* **片付け**：

  * チャンクCSVと空ディレクトリを削除
* **進捗**：

  * 後処理対象のファイル数を `total_files` とし、完了数に応じて `Sort: XX%` を上書き表示
  * 個々のファイル名は表示しない

> **外部ソート**なので、巨大なOPIDファイルでも**メモリ安定**。NVMe SSD推奨。

---

### 5. 進捗表示（％のみ）

* **表示は2行だけ**（上書き更新 → 完了時に改行）

  * `Extract: 0% … 100%`
  * `Sort: 0% … 100%`
* **ファイル名等の詳細は出さない**（大量データで視認性低下を回避）

---

### 6. 性能チューニング & 実運用のコツ

* **ストレージ**：**NVMe SSD** が最有力。HDD/USBはランダムI/Oで極端に遅い
* **ウイルス対策**：`OUTPUT_DIR` と `TEMP_SORT_DIR` を**リアルタイム保護から除外**すると大幅に高速化
* **`CHUNK_ROWS`**：メモリ余裕に合わせて 200k～1M 行へ調整（大きいほどチャンク数が減りマージが軽くなる）
* **`ENCODING`**：日本語CSVで文字化け・例外が出たら `cp932` に
* **`BUFFER_SIZE`**：8MiB程度まで引き上げると安定
* **並列化**：スクリプト自体はシングルスレッド。ソート後処理をOSのプロセス分割で並列実行する拡張余地はある（ただしI/O帯域が律速）

---

### 7. エラー/例外と安全性

* **不正行**（列不足・空行）は抽出/整列ともにスキップ
* **整列中断**：`*.sorted.tmp` で出力し、最後に `os.replace()` するため、**途中失敗で原本が壊れにくい**
* **ファイルロック**：整列時に対象CSVを開くため、他プロセスによる同時書き込みは不可（同スクリプトの多重起動は避ける）

---

### 8. 検証・再実行のポイント

* **件数検算**：抽出前後で総行数が一致するか（ZIP全レコード = 出力OPID合計）
* **順序検査**：任意のOPIDファイルで 7列目が**非減少（昇順）**になっているか
* **空/極小ファイル**：行数0/1でも整列は安全に通る
* **再実行の挙動**：

  * 同じ `OUTPUT_DIR` に対して再抽出すれば追記される→**再度ソート**が必要
  * クリーンに実験したい場合は `OUTPUT_DIR` を空にしてから実行（推奨）

---

### 9. ディレクトリ構成（例）

```
INPUT_DIR/
  ├─ OUT1-2_523347_20250205.zip
  ├─ OUT1-2_523357_20250206.zip
  └─ ...

OUTPUT_DIR/
  ├─ R7_2_000000123456.csv
  ├─ R7_2_000000123789.csv
  ├─ _sort_tmp/
  │    └─ R7_2_000000123456/
  │         ├─ chunk_00001.csv
  │         └─ chunk_00002.csv
  └─ ...
```

---

### 10. 使い方（最短手順）

1. スクリプト先頭の **設定値** を自分の環境に合わせて編集
2. 実行：

   ```
   python split_by_opid_streaming.py
   ```
3. コンソールに

   ```
   Extract: 0% … 100%
   Sort:    0% … 100%
   ```

   とだけ表示され、完了すると `OUTPUT_DIR` に **時系列昇順の `<時期>_<OPID>.csv`** が揃う

---

### 11. 将来の拡張アイデア

* **ZIPフィルタの柔軟化**：ワイルドカードや正規表現、日付レンジでの選別
* **同時ZIP読みの並列化**：I/O帯域とCPUコアに応じてバランスを取る（ただし出力先の同時書き込みは要調停）
* **ログ切替**：`VERBOSE` レベルを設け、デバッグ時のみ詳細ログを出す
* **再開機能**：途中失敗時の再開用に、完了したZIPや整列済みファイルの記録を残す

---

## まとめ

* このスクリプトは**大規模ZIP群→運行IDごと集約**を**低メモリ**で安全にこなし、
  **最後に時系列で厳密整列**する二段構えです。
* **ヘッダーは一切扱わず**、**進捗は％のみ**で静かに回る運用設計。
* temp大量生成を避けつつ、整列は**外部ソート**で堅牢に実施します。

迷ったら：**設定→実行→Extract％→Sort％→完了**。
これだけ覚えておけばOKです。
